{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mhsnur/TESIS-S2-Geomatika-FT-UGM-Muhsin-Nur-Alamsyah/blob/main/RANDOM_FOREST/RANDOM_FOREST_KOTA_BARU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQZDhA6HiaSN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k3oZIH-ifRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34053ae9-5b55-4ab5-9c6a-7aadafb4b634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEZZ5xoJinNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0394f5-da21-4619-f13e-989c5f9715e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting laspy\n",
            "  Downloading laspy-2.6.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting cloth-simulation-filter\n",
            "  Downloading cloth_simulation_filter-1.1.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Downloading laspy-2.6.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.1/86.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloth_simulation_filter-1.1.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cloth-simulation-filter, laspy\n",
            "Successfully installed cloth-simulation-filter-1.1.7 laspy-2.6.1\n",
            "Jumlah titik ground: 1784345\n",
            "Jumlah titik non-ground: 7883018\n",
            "‚úÖ Ground disimpan di: /content/drive/MyDrive/Segmented_LAS/DATA TESIS/tambah _data/KOTA BARU/ground_csf.las\n",
            "‚úÖ Non-ground disimpan di: /content/drive/MyDrive/Segmented_LAS/DATA TESIS/tambah _data/KOTA BARU/non_ground_csf.las\n"
          ]
        }
      ],
      "source": [
        "!pip install laspy cloth-simulation-filter numpy\n",
        "\n",
        "\n",
        "import laspy\n",
        "import numpy as np\n",
        "import os\n",
        "import CSF\n",
        "from scipy.spatial import cKDTree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "def csf_ground_non_ground(las_path,\n",
        "                          cloth_resolution=2.0,\n",
        "                          threshold=0.5,\n",
        "                          rigidness=6,\n",
        "                          slope_smooth=True,\n",
        "                          save_ground_path=None,\n",
        "                          save_non_ground_path=None):\n",
        "    \"\"\"\n",
        "    Gunakan CSF untuk memisahkan ground dan non-ground dari point cloud.\n",
        "    \"\"\"\n",
        "\n",
        "    las = laspy.read(las_path)\n",
        "    points = las.points\n",
        "    xyz = np.vstack((las.x, las.y, las.z)).T\n",
        "\n",
        "    csf = CSF.CSF()\n",
        "\n",
        "    csf.params.cloth_resolution = cloth_resolution\n",
        "    csf.params.threshold = threshold\n",
        "    csf.params.rigidness = rigidness\n",
        "    csf.params.bSloopSmooth = slope_smooth\n",
        "\n",
        "    csf.setPointCloud(xyz.tolist())\n",
        "\n",
        "    ground = CSF.VecInt()\n",
        "    non_ground = CSF.VecInt()\n",
        "\n",
        "    csf.do_filtering(ground, non_ground)\n",
        "\n",
        "    ground_idx = np.array(ground, dtype=int)\n",
        "    non_ground_idx = np.array(non_ground, dtype=int)\n",
        "\n",
        "    if save_ground_path:\n",
        "        las_ground = laspy.create(point_format=las.header.point_format,\n",
        "                                  file_version=las.header.version)\n",
        "        las_ground.points = points[ground_idx]\n",
        "        las_ground.header.offsets = las.header.offsets\n",
        "        las_ground.header.scales = las.header.scales\n",
        "        las_ground.write(save_ground_path)\n",
        "\n",
        "    if save_non_ground_path:\n",
        "        las_non_ground = laspy.create(point_format=las.header.point_format,\n",
        "                                      file_version=las.header.version)\n",
        "        las_non_ground.points = points[non_ground_idx]\n",
        "        las_non_ground.header.offsets = las.header.offsets\n",
        "        las_non_ground.header.scales = las.header.scales\n",
        "        las_non_ground.write(save_non_ground_path)\n",
        "\n",
        "    return ground_idx, non_ground_idx\n",
        "\n",
        "path_base = '/content/drive/MyDrive/Segmented_LAS/DATA TESIS/tambah _data/KOTA BARU'\n",
        "input_las = os.path.join(path_base, \"area_uji.las\")\n",
        "ground_output = os.path.join(path_base, \"ground_csf.las\")\n",
        "nonground_output = os.path.join(path_base, \"non_ground_csf.las\")\n",
        "\n",
        "ground_idx, non_ground_idx = csf_ground_non_ground(\n",
        "    las_path=input_las,\n",
        "    cloth_resolution=2.0,\n",
        "    threshold=0.5,\n",
        "    rigidness=6,\n",
        "    slope_smooth=True,\n",
        "    save_ground_path=ground_output,\n",
        "    save_non_ground_path=nonground_output\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Jumlah titik ground: {len(ground_idx)}\")\n",
        "print(f\"Jumlah titik non-ground: {len(non_ground_idx)}\")\n",
        "print(f\"‚úÖ Ground disimpan di: {ground_output}\")\n",
        "print(f\"‚úÖ Non-ground disimpan di: {nonground_output}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "def extract_features(las_data, k_neighbors=10):\n",
        "    xyz = np.vstack((las_data.x, las_data.y, las_data.z)).T\n",
        "    rgb = np.vstack((las_data.red, las_data.green, las_data.blue)).T\n",
        "    intensity = las_data.intensity\n",
        "\n",
        "    tree = cKDTree(xyz)\n",
        "    z_std_list = []\n",
        "    for i in range(len(xyz)):\n",
        "        _, idx = tree.query(xyz[i], k=k_neighbors)\n",
        "        neighbors = xyz[idx]\n",
        "        z_std = np.std(neighbors[:, 2])\n",
        "        z_std_list.append(z_std)\n",
        "    z_std_array = np.array(z_std_list)\n",
        "\n",
        "    features = np.hstack((\n",
        "        rgb,\n",
        "        intensity.reshape(-1, 1),\n",
        "        z_std_array.reshape(-1, 1)\n",
        "    ))\n",
        "\n",
        "    return features\n",
        "\n",
        "veg_las = laspy.read(os.path.join(path_base, \"bangunan.las\"))\n",
        "bdg_las = laspy.read(os.path.join(path_base, \"vegetasi.las\"))\n",
        "\n",
        "features_veg = extract_features(veg_las)\n",
        "features_bdg = extract_features(bdg_las)\n",
        "\n",
        "labels_veg = np.full(len(features_veg), 5)\n",
        "labels_bdg = np.full(len(features_bdg), 6)\n",
        "\n",
        "X = np.vstack((features_veg, features_bdg))\n",
        "y = np.hstack((labels_veg, labels_bdg))\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"=== Evaluasi Model RF ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "las_all = laspy.read(input_las)\n",
        "non_ground_points = laspy.create(point_format=las_all.header.point_format, file_version=las_all.header.version)\n",
        "non_ground_points.points = las_all.points[non_ground_idx]\n",
        "\n",
        "features_non_ground = extract_features(non_ground_points)\n",
        "predicted_labels = clf.predict(features_non_ground)\n",
        "\n",
        "\n",
        "final_labels = np.zeros(len(las_all.points), dtype=np.uint8)\n",
        "final_labels[ground_idx] = 2\n",
        "final_labels[non_ground_idx] = predicted_labels\n",
        "\n",
        "\n",
        "final_las = laspy.create(point_format=las_all.header.point_format, file_version=las_all.header.version)\n",
        "final_las.points = las_all.points\n",
        "final_las.classification = final_labels\n",
        "final_las.header.offsets = las_all.header.offsets\n",
        "final_las.header.scales = las_all.header.scales\n",
        "\n",
        "output_final = os.path.join(path_base, \"hasil_segmentasi_rf.las\")\n",
        "final_las.write(output_final)\n",
        "\n",
        "print(f\"‚úÖ Hasil klasifikasi final disimpan di: {output_final}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7poL9x7jGJP",
        "outputId": "96f608c3-8b0f-446f-e9d0-6bf8538a1fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Evaluasi Model RF ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       0.99      0.99      0.99    315341\n",
            "           6       0.96      0.96      0.96     81967\n",
            "\n",
            "    accuracy                           0.98    397308\n",
            "   macro avg       0.97      0.97      0.97    397308\n",
            "weighted avg       0.98      0.98      0.98    397308\n",
            "\n",
            "[[311960   3381]\n",
            " [  3565  78402]]\n",
            "‚úÖ Hasil klasifikasi final disimpan di: /content/drive/MyDrive/Segmented_LAS/DATA TESIS/tambah _data/KOTA BARU/hasil_segmentasi_rf.las\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irGR6-YxPqGe",
        "outputId": "bd106187-5b34-46a9-ae20-c666a28342a4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Mengekstraksi fitur (RGB + Intensitas + Geometri)...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3120970/3120970 [11:37<00:00, 4476.49it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Mengekstraksi fitur (RGB + Intensitas + Geometri)...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4181354/4181354 [15:24<00:00, 4523.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Ekstraksi fitur selesai.\n",
            "Total data training: 7302324 titik.\n",
            "\n",
            "=== üìà Evaluasi Model Random Forest ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           5       1.00      1.00      1.00    624194\n",
            "           6       1.00      1.00      1.00    836271\n",
            "\n",
            "    accuracy                           1.00   1460465\n",
            "   macro avg       1.00      1.00      1.00   1460465\n",
            "weighted avg       1.00      1.00      1.00   1460465\n",
            "\n",
            "[[623295    899]\n",
            " [  1172 835099]]\n",
            "üîç Mengekstraksi fitur (RGB + Intensitas + Geometri)...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12620969/12620969 [45:19<00:00, 4641.04it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Hasil klasifikasi final disimpan di: /content/drive/MyDrive/Segmented_LAS/DATA TESIS/tambah _data/KOTA BARU/hasil_segmentasi_RF_TANPA_density.las\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================\n",
        "# 4Ô∏è‚É£ EKSTRAKSI FITUR (tanpa density)\n",
        "# ============================================\n",
        "def extract_features(las_data, ground_z_mean=None, k_neighbors=40):\n",
        "    xyz = np.vstack((las_data.x, las_data.y, las_data.z)).T\n",
        "    intensity = las_data.intensity.astype(np.float32)\n",
        "\n",
        "    # RGB Normalisasi\n",
        "    if hasattr(las_data, \"red\") and hasattr(las_data, \"green\") and hasattr(las_data, \"blue\"):\n",
        "        rgb = np.vstack((las_data.red, las_data.green, las_data.blue)).T.astype(np.float32)\n",
        "        rgb_norm = rgb / 65535.0 if rgb.max() > 1 else rgb / 255.0\n",
        "    else:\n",
        "        rgb_norm = np.zeros((len(xyz), 3), dtype=np.float32)\n",
        "\n",
        "    # Normalisasi intensitas\n",
        "    intensity /= np.percentile(intensity, 99)\n",
        "\n",
        "    tree = cKDTree(xyz)\n",
        "    z_std_list, slope_list, normal_z_list, rel_h_list, z_mean_list = [], [], [], [], []\n",
        "\n",
        "    print(\"üîç Mengekstraksi fitur (RGB + Intensitas + Geometri)...\")\n",
        "    for i in tqdm(range(len(xyz))):\n",
        "        _, idx = tree.query(xyz[i], k=k_neighbors)\n",
        "        neighbors = xyz[idx]\n",
        "\n",
        "        # Z_STD (variasi tinggi lokal)\n",
        "        z_std = np.std(neighbors[:, 2])\n",
        "        z_mean = np.mean(neighbors[:, 2])\n",
        "\n",
        "        # NORMAL & SLOPE\n",
        "        cov = np.cov(neighbors.T)\n",
        "        eigvals, eigvecs = np.linalg.eigh(cov)\n",
        "        normal = eigvecs[:, np.argmin(eigvals)]\n",
        "        normal_z = abs(normal[2])\n",
        "        slope = np.degrees(np.arccos(normal_z))\n",
        "\n",
        "        # RELATIVE HEIGHT\n",
        "        if ground_z_mean is not None:\n",
        "            rel_h = xyz[i, 2] - ground_z_mean\n",
        "        else:\n",
        "            rel_h = xyz[i, 2] - np.min(neighbors[:, 2])\n",
        "\n",
        "        z_std_list.append(z_std)\n",
        "        slope_list.append(slope)\n",
        "        normal_z_list.append(normal_z)\n",
        "        rel_h_list.append(rel_h)\n",
        "        z_mean_list.append(z_mean)\n",
        "\n",
        "    # Gabungkan semua fitur\n",
        "    features = np.hstack((\n",
        "        rgb_norm,\n",
        "        intensity.reshape(-1, 1),\n",
        "        np.array(z_std_list).reshape(-1, 1),\n",
        "        np.array(slope_list).reshape(-1, 1),\n",
        "        np.array(normal_z_list).reshape(-1, 1),\n",
        "        np.array(rel_h_list).reshape(-1, 1),\n",
        "        np.array(z_mean_list).reshape(-1, 1)\n",
        "    ))\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 5Ô∏è‚É£ DATA TRAINING (VEGETASI & BANGUNAN)\n",
        "# ============================================\n",
        "veg_las = laspy.read(os.path.join(path_base, \"VEGETASI_1.las\"))\n",
        "bdg_las = laspy.read(os.path.join(path_base, \"BANGUNAN_1.las\"))\n",
        "\n",
        "features_veg = extract_features(veg_las)\n",
        "features_bdg = extract_features(bdg_las)\n",
        "\n",
        "labels_veg = np.full(len(features_veg), 5)  # Vegetasi\n",
        "labels_bdg = np.full(len(features_bdg), 6)  # Bangunan\n",
        "\n",
        "X = np.vstack((features_veg, features_bdg))\n",
        "y = np.hstack((labels_veg, labels_bdg))\n",
        "\n",
        "print(\"\\n‚úÖ Ekstraksi fitur selesai.\")\n",
        "print(f\"Total data training: {len(X)} titik.\")\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 6Ô∏è‚É£ TRAIN RANDOM FOREST\n",
        "# ============================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=250,\n",
        "    max_depth=22,\n",
        "    min_samples_leaf=3,\n",
        "    bootstrap=True,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"\\n=== üìà Evaluasi Model Random Forest ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 7Ô∏è‚É£ KLASIFIKASI SELURUH NON-GROUND\n",
        "# ============================================\n",
        "las_all = laspy.read(input_las)\n",
        "non_ground_points = laspy.create(point_format=las_all.header.point_format,\n",
        "                                 file_version=las_all.header.version)\n",
        "non_ground_points.points = las_all.points[non_ground_idx]\n",
        "\n",
        "# Ambil rata-rata tinggi ground untuk fitur relative height\n",
        "ground_z_mean = np.mean(las_all.z[ground_idx])\n",
        "\n",
        "features_non_ground = extract_features(non_ground_points, ground_z_mean=ground_z_mean)\n",
        "predicted_labels = clf.predict(features_non_ground)\n",
        "\n",
        "# Gabungkan semua hasil\n",
        "final_labels = np.zeros(len(las_all.points), dtype=np.uint8)\n",
        "final_labels[ground_idx] = 2  # ground\n",
        "final_labels[non_ground_idx] = predicted_labels\n",
        "\n",
        "# Simpan hasil akhir\n",
        "final_las = laspy.create(point_format=las_all.header.point_format,\n",
        "                         file_version=las_all.header.version)\n",
        "final_las.points = las_all.points\n",
        "final_las.classification = final_labels\n",
        "final_las.header.offsets = las_all.header.offsets\n",
        "final_las.header.scales = las_all.header.scales\n",
        "\n",
        "output_final = os.path.join(path_base, \"hasil_segmentasi_RF_TANPA_density.las\")\n",
        "final_las.write(output_final)\n",
        "\n",
        "print(f\"\\n‚úÖ Hasil klasifikasi final disimpan di: {output_final}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cERVlJE2tu6-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOevm3Fgt8vy/6wuu3Ilsmc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}